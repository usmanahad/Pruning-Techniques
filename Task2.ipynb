{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba76c163",
   "metadata": {
    "id": "ba76c163"
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68375d44",
   "metadata": {
    "id": "68375d44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Umer/Desktop/aiedge/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e3ca7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7e3ca7d",
    "outputId": "2ee6114c-4f94-4ebc-db42-5f1acc306b84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/foxunderground/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n",
      "Using cache found in /home/foxunderground/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "model_cifar10 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True).to(device)\n",
    "model_cifar100 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg16_bn\", pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3292a82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3292a82",
    "outputId": "f61ebc06-3ccb-47ee-f514-7bb78a4c52e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::conv2d         0.02%      36.250us        67.29%     111.156ms       8.550ms       0.000us         0.00%      35.086ms       2.699ms            13  \n",
      "                                      aten::convolution         0.06%      94.199us        67.27%     111.120ms       8.548ms       0.000us         0.00%      35.086ms       2.699ms            13  \n",
      "                                     aten::_convolution         0.12%     205.640us        67.21%     111.025ms       8.540ms       0.000us         0.00%      35.086ms       2.699ms            13  \n",
      "                                aten::cudnn_convolution        38.39%      63.419ms        61.17%     101.051ms       7.773ms      13.999ms        69.96%      32.577ms       2.506ms            13  \n",
      "                                       cudaLaunchKernel         4.52%       7.465ms        47.23%      78.016ms     780.157us       0.000us         0.00%      19.142ms     191.416us           100  \n",
      "                       Runtime Triggered Module Loading        44.75%      73.924ms        44.75%      73.924ms       3.360ms      10.411ms        52.03%      10.411ms     473.242us            22  \n",
      "                                            aten::relu_         0.05%      80.200us        18.39%      30.376ms       2.025ms       0.000us         0.00%       2.480ms     165.344us            15  \n",
      "                                       aten::clamp_min_         0.11%     175.720us        18.34%      30.296ms       2.020ms       1.448ms         7.24%       2.480ms     165.344us            15  \n",
      "                                           aten::linear         0.01%      21.630us         7.82%      12.918ms       4.306ms       0.000us         0.00%     141.944us      47.315us             3  \n",
      "                                            aten::addmm         0.92%       1.521ms         7.78%      12.850ms       4.283ms      76.667us         0.38%     141.944us      47.315us             3  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 165.196ms\n",
      "Self CUDA time total: 20.009ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaDeviceSynchronize        83.51%      16.201ms        83.51%      16.201ms      16.201ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                           aten::conv2d         0.10%      19.880us         9.89%       1.919ms     147.583us       0.000us         0.00%      14.822ms       1.140ms            13  \n",
      "                                      aten::convolution         0.21%      41.520us         9.79%       1.899ms     146.053us       0.000us         0.00%      14.822ms       1.140ms            13  \n",
      "                                     aten::_convolution         0.52%     101.360us         9.57%       1.857ms     142.860us       0.000us         0.00%      14.822ms       1.140ms            13  \n",
      "                                aten::cudnn_convolution         1.97%     382.970us         7.29%       1.413ms     108.721us      13.137ms        68.56%      13.352ms       1.027ms            13  \n",
      "                                       cudaLaunchKernel         5.19%       1.008ms         5.19%       1.008ms      10.078us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                Activity Buffer Request         3.09%     598.938us         3.09%     598.938us     598.938us     215.130us         1.12%     215.130us     215.130us             1  \n",
      "                                       aten::batch_norm         0.10%      18.810us         2.98%     577.827us      44.448us       0.000us         0.00%       2.438ms     187.514us            13  \n",
      "                           aten::_batch_norm_impl_index         0.17%      33.590us         2.88%     559.017us      43.001us       0.000us         0.00%       2.438ms     187.514us            13  \n",
      "                                 aten::cudnn_batch_norm         0.98%     189.199us         2.71%     525.427us      40.417us       2.438ms        12.72%       2.438ms     187.514us            13  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 19.400ms\n",
      "Self CUDA time total: 19.162ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity\n",
    "\n",
    "model_cifar10.eval()\n",
    "inputs = torch.randn(256, 3, 32, 32).to(device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if torch.cuda.is_available() else [ProfilerActivity.CPU]) as prof:\n",
    "    with torch.no_grad():\n",
    "        model_cifar10(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "model_cifar100.eval()\n",
    "inputs = torch.randn(256, 3, 32, 32).to(device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if torch.cuda.is_available() else [ProfilerActivity.CPU]) as prof:\n",
    "    with torch.no_grad():\n",
    "        model_cifar100(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee229ff",
   "metadata": {
    "id": "9ee229ff"
   },
   "outputs": [],
   "source": [
    "transform_train_c10 = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                        (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test_c10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset_c10 = torchvision.datasets.CIFAR10(root='./data/cifar10', train=False, download=True, transform=transform_train_c10)\n",
    "testset_c10 = torchvision.datasets.CIFAR10(root='./data/cifar10', train=False, download=True, transform=transform_test_c10)\n",
    "trainloader_c10 = DataLoader(trainset_c10, batch_size=64, shuffle=True, num_workers=0)\n",
    "testloader_c10 = DataLoader(testset_c10, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c921256",
   "metadata": {
    "id": "7c921256"
   },
   "outputs": [],
   "source": [
    "mean_c100 = [0.5070, 0.4865, 0.4409]\n",
    "std_c100 = [0.2673, 0.2564, 0.2761]\n",
    "\n",
    "train_transform_c100 = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_c100, std_c100)\n",
    "])\n",
    "\n",
    "test_transform_c100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_c100, std_c100)\n",
    "])\n",
    "\n",
    "trainset_c100 = torchvision.datasets.CIFAR100(root=\"./data/cifar100\", train=True, download=True, transform=train_transform_c100)\n",
    "testset_c100 = torchvision.datasets.CIFAR100(root=\"./data/cifar100\", train=False, download=True, transform=test_transform_c100)\n",
    "\n",
    "trainloader_c100 = DataLoader(trainset_c100, batch_size=64, shuffle=True, num_workers=0)\n",
    "testloader_c100 = DataLoader(testset_c100, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37281c",
   "metadata": {
    "id": "0f37281c"
   },
   "source": [
    "# Pruning Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "giX5uRw9HPJz",
   "metadata": {
    "id": "giX5uRw9HPJz"
   },
   "outputs": [],
   "source": [
    "def get_conv_modules(model):\n",
    "    convs = []\n",
    "    names = []\n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            convs.append(m)\n",
    "            names.append(n)\n",
    "    return convs, names\n",
    "\n",
    "def find_following_bn(model, conv_name):\n",
    "    modlist = list(model.named_modules())\n",
    "    for i, (n, m) in enumerate(modlist):\n",
    "        if n == conv_name:\n",
    "            for j in range(i+1, min(i+6, len(modlist))):\n",
    "                if isinstance(modlist[j][1], nn.BatchNorm2d):\n",
    "                    return modlist[j][0], modlist[j][1]\n",
    "    return None, None\n",
    "\n",
    "def get_parent_module(model, layer_name):\n",
    "    parent_module = model\n",
    "    name_parts = layer_name.split('.')\n",
    "    for part in name_parts[:-1]:\n",
    "        if part.isdigit():\n",
    "            parent_module = parent_module[int(part)]\n",
    "        else:\n",
    "            parent_module = getattr(parent_module, part)\n",
    "    return parent_module, name_parts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nZyLLSbSaNNK",
   "metadata": {
    "id": "nZyLLSbSaNNK"
   },
   "outputs": [],
   "source": [
    "def prune_layer_regression(layer, inputs, keep_ratio=0.3, device='cpu'):\n",
    "    layer_cpu = layer.cpu()\n",
    "    inputs_cpu = inputs.cpu()\n",
    "    N, C_in, H, W = inputs_cpu.shape\n",
    "    kh, kw = layer_cpu.kernel_size\n",
    "    stride = layer_cpu.stride\n",
    "    padding = layer_cpu.padding\n",
    "    C_out = layer_cpu.out_channels\n",
    "    X_unf = F.unfold(inputs_cpu, kernel_size=(kh, kw), padding=padding, stride=stride)\n",
    "    L = X_unf.shape[-1]\n",
    "    X_unf = X_unf.permute(0, 2, 1).reshape(-1, C_in * kh * kw)\n",
    "    W = layer_cpu.weight.data\n",
    "    W_mat = W.view(C_out, -1).t()\n",
    "    Y = X_unf @ W_mat\n",
    "    scores = torch.zeros(C_in, dtype=torch.float64)\n",
    "    for i in range(C_in):\n",
    "        start = i * kh * kw\n",
    "        end = (i + 1) * kh * kw\n",
    "        Xi = X_unf[:, start:end]\n",
    "        Wi = W[:, i, :, :].reshape(C_out, -1)\n",
    "        Zi = Xi @ Wi.t()\n",
    "        scores[i] = torch.abs((Zi.double() * Y.double()).sum())\n",
    "    num_keep = max(1, int(C_in * keep_ratio))\n",
    "    _, keep_idx = torch.topk(scores, num_keep, largest=True)\n",
    "    keep_idx_sorted, _ = torch.sort(keep_idx)\n",
    "    cols = []\n",
    "    for i in keep_idx_sorted.tolist():\n",
    "        cols.extend(range(i * kh * kw, (i + 1) * kh * kw))\n",
    "    cols = torch.tensor(cols, dtype=torch.long)\n",
    "    X_reduced = X_unf[:, cols]\n",
    "    sol = torch.linalg.lstsq(X_reduced.float(), Y.float()).solution\n",
    "    W_recon = sol.t().reshape(C_out, num_keep, kh, kw).contiguous()\n",
    "    new_layer = nn.Conv2d(\n",
    "        in_channels=num_keep,\n",
    "        out_channels=C_out,\n",
    "        kernel_size=layer_cpu.kernel_size,\n",
    "        stride=layer_cpu.stride,\n",
    "        padding=layer_cpu.padding,\n",
    "        bias=(layer_cpu.bias is not None)\n",
    "    )\n",
    "    new_layer.weight.data = W_recon\n",
    "    if layer_cpu.bias is not None:\n",
    "        new_layer.bias.data = layer_cpu.bias.data.clone()\n",
    "    return new_layer.to(device), keep_idx_sorted.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925tYPDTaT9P",
   "metadata": {
    "id": "925tYPDTaT9P"
   },
   "outputs": [],
   "source": [
    "def prune_output_channels(layer, keep_idx, device):\n",
    "    keep_idx_sorted, _ = torch.sort(keep_idx)\n",
    "    new_layer = nn.Conv2d(\n",
    "        in_channels=layer.in_channels,\n",
    "        out_channels=len(keep_idx_sorted),\n",
    "        kernel_size=layer.kernel_size,\n",
    "        stride=layer.stride,\n",
    "        padding=layer.padding,\n",
    "        bias=(layer.bias is not None)\n",
    "    )\n",
    "    new_layer.weight.data = layer.weight.data[keep_idx_sorted].clone()\n",
    "    if layer.bias is not None:\n",
    "        new_layer.bias.data = layer.bias.data[keep_idx_sorted].clone()\n",
    "    return new_layer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "UmC0QOImaWWJ",
   "metadata": {
    "id": "UmC0QOImaWWJ"
   },
   "outputs": [],
   "source": [
    "def prune_batchnorm(bn_layer, keep_idx, device):\n",
    "    keep_idx_sorted, _ = torch.sort(keep_idx)\n",
    "    new_bn = nn.BatchNorm2d(len(keep_idx_sorted))\n",
    "    new_bn.weight.data = bn_layer.weight.data[keep_idx_sorted].clone()\n",
    "    new_bn.bias.data = bn_layer.bias.data[keep_idx_sorted].clone()\n",
    "    new_bn.running_mean = bn_layer.running_mean[keep_idx_sorted].clone()\n",
    "    new_bn.running_var = bn_layer.running_var[keep_idx_sorted].clone()\n",
    "    new_bn.num_batches_tracked = bn_layer.num_batches_tracked.clone()\n",
    "    return new_bn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cMJartDjaYVb",
   "metadata": {
    "id": "cMJartDjaYVb"
   },
   "outputs": [],
   "source": [
    "def sequential_prune(model, data_loader, device, overall_sparsity=0.7, calib_batches=1):\n",
    "    if overall_sparsity <= 0:\n",
    "        return model\n",
    "\n",
    "    print(f\"Starting sequential pruning with target sparsity: {overall_sparsity*100:.1f}%\")\n",
    "    model.eval()\n",
    "    conv_layers = [(n, m) for n, m in model.named_modules() if isinstance(m, nn.Conv2d)]\n",
    "    keep_ratio = 1.0 - overall_sparsity\n",
    "    data_iter = iter(data_loader)\n",
    "    calib_images, _ = next(data_iter)\n",
    "    calib_images = calib_images.to(device)\n",
    "    original_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    original_conv_params = sum(m.weight.numel() for _, m in conv_layers)\n",
    "    for idx, (layer_name, layer) in enumerate(conv_layers):\n",
    "        if idx == 0:\n",
    "            print(f\"Skip first layer (takes raw image input)\\n\")\n",
    "            continue\n",
    "        print(\"=========================================================================================\")\n",
    "        print(f\"\\nProcessing layer {idx+1}: {layer_name}\")\n",
    "\n",
    "        print(f\"  Input channels: {layer.in_channels}, Output channels: {layer.out_channels}\")\n",
    "        prev_layer_name, prev_layer = conv_layers[idx - 1]\n",
    "        layer_inputs = []\n",
    "        def capture_input(module, inp, outp):\n",
    "            layer_inputs.append(inp[0].detach().cpu())\n",
    "        handle = layer.register_forward_hook(capture_input)\n",
    "        with torch.no_grad():\n",
    "            _ = model(calib_images)\n",
    "        handle.remove()\n",
    "        inputs = layer_inputs[0]\n",
    "\n",
    "        print(f\"  Pruning with keep_ratio={keep_ratio:.2f} (target sparsity={overall_sparsity:.2f})\")\n",
    "        new_layer, keep_idx = prune_layer_regression(layer, inputs, keep_ratio=keep_ratio, device=device)\n",
    "        parent_module, attr_name = get_parent_module(model, layer_name)\n",
    "        setattr(parent_module, attr_name, new_layer)\n",
    "\n",
    "        print(f\"  Current layer: {layer.in_channels} -> {new_layer.in_channels} input channels\")\n",
    "        prev_parent, prev_attr = get_parent_module(model, prev_layer_name)\n",
    "        prev_layer = getattr(prev_parent, prev_attr)\n",
    "        pruned_prev_layer = prune_output_channels(prev_layer, keep_idx, device)\n",
    "        setattr(prev_parent, prev_attr, pruned_prev_layer)\n",
    "\n",
    "        print(f\"  Previous layer: {prev_layer.out_channels} -> {pruned_prev_layer.out_channels} output channels\")\n",
    "        bn_name, bn_layer = find_following_bn(model, prev_layer_name)\n",
    "        if bn_name is not None and bn_layer is not None:\n",
    "            print(f\"  Pruning BatchNorm layer: {bn_name}\")\n",
    "            bn_parent, bn_attr = get_parent_module(model, bn_name)\n",
    "            pruned_bn = prune_batchnorm(bn_layer, keep_idx, device)\n",
    "            setattr(bn_parent, bn_attr, pruned_bn)\n",
    "            print(f\"  BatchNorm: {bn_layer.num_features} -> {pruned_bn.num_features} channels\")\n",
    "        print(\"=========================================================================================\")\n",
    "        print()\n",
    "\n",
    "    # Calculate final statistics for debugging\n",
    "    final_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    final_conv_params = sum(m.weight.numel() for _, m in model.named_modules() if isinstance(m, nn.Conv2d))\n",
    "    nonzero_params = sum((p != 0).sum().item() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"=== Pruning Results ===\")\n",
    "    print(f\"Original total params: {original_params:,}\")\n",
    "    print(f\"Final total params: {final_params:,}\")\n",
    "    print(f\"Reduction: {(1 - final_params/original_params)*100:.2f}%\")\n",
    "    print(f\"\\nOriginal conv params: {original_conv_params:,}\")\n",
    "    print(f\"Final conv params: {final_conv_params:,}\")\n",
    "    print(f\"Conv reduction: {(1 - final_conv_params/original_conv_params)*100:.2f}%\")\n",
    "    print(f\"\\nTarget sparsity: {overall_sparsity*100:.1f}%\")\n",
    "    print(f\"Achieved reduction: {(1 - final_params/original_params)*100:.2f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    print(\"Sequential pruning finished.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b10791",
   "metadata": {
    "id": "a7b10791",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing - CIFAR10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b771ff9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b771ff9f",
    "outputId": "20c7d104-2c40-48c0-c910-5c6808e996b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential pruning with target sparsity: 70.0%\n",
      "Skip first layer (takes raw image input)\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 2: features.3\n",
      "  Input channels: 64, Output channels: 64\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 64 -> 19 input channels\n",
      "  Previous layer: 64 -> 19 output channels\n",
      "  Pruning BatchNorm layer: features.1\n",
      "  BatchNorm: 64 -> 19 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 3: features.7\n",
      "  Input channels: 64, Output channels: 128\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 64 -> 19 input channels\n",
      "  Previous layer: 64 -> 19 output channels\n",
      "  Pruning BatchNorm layer: features.4\n",
      "  BatchNorm: 64 -> 19 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 4: features.10\n",
      "  Input channels: 128, Output channels: 128\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 128 -> 38 input channels\n",
      "  Previous layer: 128 -> 38 output channels\n",
      "  Pruning BatchNorm layer: features.8\n",
      "  BatchNorm: 128 -> 38 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 5: features.14\n",
      "  Input channels: 128, Output channels: 256\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 128 -> 38 input channels\n",
      "  Previous layer: 128 -> 38 output channels\n",
      "  Pruning BatchNorm layer: features.11\n",
      "  BatchNorm: 128 -> 38 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 6: features.17\n",
      "  Input channels: 256, Output channels: 256\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 256 -> 76 input channels\n",
      "  Previous layer: 256 -> 76 output channels\n",
      "  Pruning BatchNorm layer: features.15\n",
      "  BatchNorm: 256 -> 76 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 7: features.20\n",
      "  Input channels: 256, Output channels: 256\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 256 -> 76 input channels\n",
      "  Previous layer: 256 -> 76 output channels\n",
      "  Pruning BatchNorm layer: features.18\n",
      "  BatchNorm: 256 -> 76 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 8: features.24\n",
      "  Input channels: 256, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 256 -> 76 input channels\n",
      "  Previous layer: 256 -> 76 output channels\n",
      "  Pruning BatchNorm layer: features.21\n",
      "  BatchNorm: 256 -> 76 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 9: features.27\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.25\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 10: features.30\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.28\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 11: features.34\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.31\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 12: features.37\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.35\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 13: features.40\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.38\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "======================================================================\n",
      "=== Pruning Results ===\n",
      "Original total params: 15,253,578\n",
      "Final total params: 2,340,915\n",
      "Reduction: 84.65%\n",
      "\n",
      "Original conv params: 14,710,464\n",
      "Final conv params: 1,805,616\n",
      "Conv reduction: 87.73%\n",
      "\n",
      "Target sparsity: 70.0%\n",
      "Achieved reduction: 84.65%\n",
      "======================================================================\n",
      "\n",
      "Sequential pruning finished.\n"
     ]
    }
   ],
   "source": [
    "pruned_c10 = sequential_prune(model_cifar10, trainloader_c10, device, overall_sparsity=0.7, calib_batches=6)\n",
    "# torch.save(pruned_c10.state_dict(), 'vgg16bn_pruned_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gkOAYBO4JPiY",
   "metadata": {
    "id": "gkOAYBO4JPiY"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(pruned.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pUE9oOu-Hjdj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUE9oOu-Hjdj",
    "outputId": "88db4c51-35da-46ed-f69f-fe1c7c325756"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 24.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 2.0352 | Train Acc: 24.22% | Val Loss: 1.8417 | Val Acc: 28.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] | Train Loss: 1.6911 | Train Acc: 33.45% | Val Loss: 1.6119 | Val Acc: 38.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:07<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] | Train Loss: 1.5610 | Train Acc: 41.37% | Val Loss: 1.5131 | Val Acc: 42.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] | Train Loss: 1.4229 | Train Acc: 46.92% | Val Loss: 1.2982 | Val Acc: 52.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] | Train Loss: 1.3201 | Train Acc: 52.68% | Val Loss: 1.1988 | Val Acc: 56.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 26.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] | Train Loss: 1.2241 | Train Acc: 56.71% | Val Loss: 1.4083 | Val Acc: 49.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 24.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] | Train Loss: 1.1424 | Train Acc: 59.75% | Val Loss: 1.0781 | Val Acc: 61.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] | Train Loss: 1.0936 | Train Acc: 61.48% | Val Loss: 1.0255 | Val Acc: 64.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] | Train Loss: 1.0544 | Train Acc: 63.04% | Val Loss: 0.9010 | Val Acc: 69.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Train Loss: 1.0053 | Train Acc: 65.14% | Val Loss: 1.0244 | Val Acc: 64.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] | Train Loss: 0.9689 | Train Acc: 66.80% | Val Loss: 0.9897 | Val Acc: 65.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] | Train Loss: 0.9570 | Train Acc: 67.53% | Val Loss: 0.9175 | Val Acc: 67.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] | Train Loss: 0.9043 | Train Acc: 69.59% | Val Loss: 0.9594 | Val Acc: 67.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] | Train Loss: 0.8987 | Train Acc: 69.57% | Val Loss: 0.8752 | Val Acc: 69.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] | Train Loss: 0.8658 | Train Acc: 70.89% | Val Loss: 0.8662 | Val Acc: 71.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] | Train Loss: 0.8593 | Train Acc: 70.94% | Val Loss: 0.8908 | Val Acc: 69.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] | Train Loss: 0.8359 | Train Acc: 72.54% | Val Loss: 1.0518 | Val Acc: 67.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] | Train Loss: 0.8383 | Train Acc: 72.38% | Val Loss: 0.7594 | Val Acc: 74.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] | Train Loss: 0.8079 | Train Acc: 72.99% | Val Loss: 0.7975 | Val Acc: 72.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:06<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Train Loss: 0.7709 | Train Acc: 74.32% | Val Loss: 0.7344 | Val Acc: 75.37%\n"
     ]
    }
   ],
   "source": [
    "pruned_c10.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pruned_c10.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in tqdm(trainloader_c10):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = pruned_c10(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = 100.0 * correct / total\n",
    "\n",
    "    pruned_c10.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in testloader_c10:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = pruned_c10(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_loss /= val_total\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jvL8A1FLHl3M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvL8A1FLHl3M",
    "outputId": "6487567e-12e0-48cb-d80f-ffad25a674c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              inference         0.00%       0.000us         0.00%       0.000us       0.000us       2.611ms       113.81%       2.611ms       2.611ms             1  \n",
      "                                              inference        16.99%       1.067ms        99.59%       6.256ms       6.256ms       0.000us         0.00%       2.294ms       2.294ms             1  \n",
      "                                           aten::conv2d         1.15%      72.240us        47.51%       2.984ms     229.574us       0.000us         0.00%       1.768ms     136.031us            13  \n",
      "                                      aten::convolution         2.88%     180.688us        46.36%       2.912ms     224.017us       0.000us         0.00%       1.768ms     136.031us            13  \n",
      "                                     aten::_convolution         3.09%     193.952us        43.48%       2.732ms     210.118us       0.000us         0.00%       1.768ms     136.031us            13  \n",
      "                                aten::cudnn_convolution        11.22%     704.589us        35.37%       2.222ms     170.902us       1.694ms        73.83%       1.694ms     130.276us            13  \n",
      "                                   volta_sgemm_64x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     587.923us        25.63%     587.923us      97.987us             6  \n",
      "                                       aten::batch_norm         0.48%      30.242us        14.99%     941.344us      72.411us       0.000us         0.00%     344.152us      26.473us            13  \n",
      "                           aten::_batch_norm_impl_index         0.93%      58.238us        14.50%     911.102us      70.085us       0.000us         0.00%     344.152us      26.473us            13  \n",
      "                                 aten::cudnn_batch_norm         6.82%     428.595us        13.58%     852.864us      65.605us     344.152us        15.00%     344.152us      26.473us            13  \n",
      "void cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float,...         0.00%       0.000us         0.00%       0.000us       0.000us     344.152us        15.00%     344.152us      43.019us             8  \n",
      "void cudnn::winograd_nonfused::winogradForwardOutput...         0.00%       0.000us         0.00%       0.000us       0.000us     325.849us        14.21%     325.849us      40.731us             8  \n",
      "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us     294.331us        12.83%     294.331us      42.047us             7  \n",
      "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us     287.511us        12.53%     287.511us      35.939us             8  \n",
      "                                  volta_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     197.980us         8.63%     197.980us      98.990us             2  \n",
      "                                           aten::linear         0.26%      16.534us         9.65%     606.302us     202.101us       0.000us         0.00%     101.021us      33.674us             3  \n",
      "                                            aten::addmm         2.69%     168.963us         8.79%     552.452us     184.151us     101.021us         4.40%     101.021us      33.674us             3  \n",
      "                                             aten::add_         2.51%     157.910us         4.09%     256.845us      19.757us      74.814us         3.26%      74.814us       5.755us            13  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      74.814us         3.26%      74.814us       9.352us             8  \n",
      "                                  volta_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.255us         2.98%      68.255us      34.128us             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 6.282ms\n",
      "Self CUDA time total: 2.294ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "imgs, labels = next(iter(testloader_c10))\n",
    "imgs = imgs.to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"inference\"):\n",
    "        _ = pruned_c10(imgs)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TFUwD8ZBLVlH",
   "metadata": {
    "id": "TFUwD8ZBLVlH"
   },
   "source": [
    "# Testing - CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "QsiTKoGELUow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsiTKoGELUow",
    "outputId": "72ebf31b-bfec-44dd-c42e-fc51b62e0664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential pruning with target sparsity: 70.0%\n",
      "Skip first layer (takes raw image input)\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 2: features.3\n",
      "  Input channels: 64, Output channels: 64\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 64 -> 19 input channels\n",
      "  Previous layer: 64 -> 19 output channels\n",
      "  Pruning BatchNorm layer: features.1\n",
      "  BatchNorm: 64 -> 19 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 3: features.7\n",
      "  Input channels: 64, Output channels: 128\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 64 -> 19 input channels\n",
      "  Previous layer: 64 -> 19 output channels\n",
      "  Pruning BatchNorm layer: features.4\n",
      "  BatchNorm: 64 -> 19 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 4: features.10\n",
      "  Input channels: 128, Output channels: 128\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 128 -> 38 input channels\n",
      "  Previous layer: 128 -> 38 output channels\n",
      "  Pruning BatchNorm layer: features.8\n",
      "  BatchNorm: 128 -> 38 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 5: features.14\n",
      "  Input channels: 128, Output channels: 256\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 128 -> 38 input channels\n",
      "  Previous layer: 128 -> 38 output channels\n",
      "  Pruning BatchNorm layer: features.11\n",
      "  BatchNorm: 128 -> 38 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 6: features.17\n",
      "  Input channels: 256, Output channels: 256\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 256 -> 76 input channels\n",
      "  Previous layer: 256 -> 76 output channels\n",
      "  Pruning BatchNorm layer: features.15\n",
      "  BatchNorm: 256 -> 76 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 7: features.20\n",
      "  Input channels: 256, Output channels: 256\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 256 -> 76 input channels\n",
      "  Previous layer: 256 -> 76 output channels\n",
      "  Pruning BatchNorm layer: features.18\n",
      "  BatchNorm: 256 -> 76 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 8: features.24\n",
      "  Input channels: 256, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 256 -> 76 input channels\n",
      "  Previous layer: 256 -> 76 output channels\n",
      "  Pruning BatchNorm layer: features.21\n",
      "  BatchNorm: 256 -> 76 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 9: features.27\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.25\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 10: features.30\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.28\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 11: features.34\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.31\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 12: features.37\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.35\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "=========================================================================================\n",
      "\n",
      "Processing layer 13: features.40\n",
      "  Input channels: 512, Output channels: 512\n",
      "  Pruning with keep_ratio=0.30 (target sparsity=0.70)\n",
      "  Current layer: 512 -> 153 input channels\n",
      "  Previous layer: 512 -> 153 output channels\n",
      "  Pruning BatchNorm layer: features.38\n",
      "  BatchNorm: 512 -> 153 channels\n",
      "=========================================================================================\n",
      "\n",
      "======================================================================\n",
      "=== Pruning Results ===\n",
      "Original total params: 15,299,748\n",
      "Final total params: 2,387,085\n",
      "Reduction: 84.40%\n",
      "\n",
      "Original conv params: 14,710,464\n",
      "Final conv params: 1,805,616\n",
      "Conv reduction: 87.73%\n",
      "\n",
      "Target sparsity: 70.0%\n",
      "Achieved reduction: 84.40%\n",
      "======================================================================\n",
      "\n",
      "Sequential pruning finished.\n"
     ]
    }
   ],
   "source": [
    "pruned_c100 = sequential_prune(model_cifar100, trainloader_c100, device, overall_sparsity=0.7, calib_batches=6)\n",
    "torch.save(pruned_c100.state_dict(), 'vgg16bn_pruned_100.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RKhtOhmsLeoz",
   "metadata": {
    "id": "RKhtOhmsLeoz"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(pruned_c100.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GJQqQq9fLhgI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJQqQq9fLhgI",
    "outputId": "bf555efd-69f5-45e3-e0f0-120b4690a9bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 4.2003 | Train Acc: 4.89% | Val Loss: 3.8325 | Val Acc: 8.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] | Train Loss: 3.6694 | Train Acc: 11.89% | Val Loss: 3.3167 | Val Acc: 17.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] | Train Loss: 3.3202 | Train Acc: 17.36% | Val Loss: 3.0671 | Val Acc: 22.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] | Train Loss: 3.0837 | Train Acc: 21.87% | Val Loss: 2.9157 | Val Acc: 25.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] | Train Loss: 2.9086 | Train Acc: 25.06% | Val Loss: 2.6867 | Val Acc: 28.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] | Train Loss: 2.7867 | Train Acc: 27.64% | Val Loss: 2.7608 | Val Acc: 29.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] | Train Loss: 2.6798 | Train Acc: 30.07% | Val Loss: 2.5965 | Val Acc: 31.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] | Train Loss: 2.5894 | Train Acc: 32.41% | Val Loss: 2.3547 | Val Acc: 36.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] | Train Loss: 2.5192 | Train Acc: 33.72% | Val Loss: 2.4645 | Val Acc: 35.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Train Loss: 2.4545 | Train Acc: 35.30% | Val Loss: 2.4040 | Val Acc: 36.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 23.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] | Train Loss: 2.4048 | Train Acc: 36.38% | Val Loss: 2.4090 | Val Acc: 36.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] | Train Loss: 2.3582 | Train Acc: 37.69% | Val Loss: 2.3166 | Val Acc: 38.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] | Train Loss: 2.3112 | Train Acc: 38.97% | Val Loss: 2.3250 | Val Acc: 38.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] | Train Loss: 2.2669 | Train Acc: 39.69% | Val Loss: 2.3088 | Val Acc: 40.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] | Train Loss: 2.2232 | Train Acc: 40.83% | Val Loss: 2.2803 | Val Acc: 39.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] | Train Loss: 2.1975 | Train Acc: 41.57% | Val Loss: 2.0889 | Val Acc: 43.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 23.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] | Train Loss: 2.1613 | Train Acc: 42.42% | Val Loss: 2.0702 | Val Acc: 44.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:31<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] | Train Loss: 2.1314 | Train Acc: 43.21% | Val Loss: 2.2170 | Val Acc: 41.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:32<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] | Train Loss: 2.1023 | Train Acc: 44.03% | Val Loss: 2.1594 | Val Acc: 43.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:33<00:00, 23.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Train Loss: 2.0783 | Train Acc: 44.58% | Val Loss: 2.1320 | Val Acc: 43.82%\n"
     ]
    }
   ],
   "source": [
    "pruned_c100.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pruned_c100.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in tqdm(trainloader_c100):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = pruned_c100(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = 100.0 * correct / total\n",
    "\n",
    "    pruned_c100.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in testloader_c100:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = pruned_c100(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_loss /= val_total\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pq30UUJSLk06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pq30UUJSLk06",
    "outputId": "32681dba-7e52-4882-bab1-36817d119420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              inference         0.00%       0.000us         0.00%       0.000us       0.000us       1.047ms       104.14%       1.047ms       1.047ms             1  \n",
      "                                              inference        16.79%       1.000ms        98.55%       5.872ms       5.872ms       0.000us         0.00%       1.006ms       1.006ms             1  \n",
      "                                           aten::conv2d         0.84%      50.273us        50.93%       3.034ms     233.415us       0.000us         0.00%     676.688us      52.053us            13  \n",
      "                                      aten::convolution         2.38%     141.654us        50.09%       2.984ms     229.548us       0.000us         0.00%     676.688us      52.053us            13  \n",
      "                                     aten::_convolution         2.77%     164.904us        47.71%       2.842ms     218.651us       0.000us         0.00%     676.688us      52.053us            13  \n",
      "                                aten::cudnn_convolution        10.33%     615.680us        39.48%       2.352ms     180.919us     661.200us        65.75%     661.200us      50.862us            13  \n",
      "                                   volta_sgemm_64x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     270.809us        26.93%     270.809us     135.404us             2  \n",
      "                                       aten::batch_norm         0.75%      44.708us        15.34%     914.002us      70.308us       0.000us         0.00%     193.467us      14.882us            13  \n",
      "                           aten::_batch_norm_impl_index         0.94%      55.708us        14.59%     869.294us      66.869us       0.000us         0.00%     193.467us      14.882us            13  \n",
      "                                 aten::cudnn_batch_norm         6.90%     411.302us        13.66%     813.586us      62.584us     193.467us        19.24%     193.467us      14.882us            13  \n",
      "void cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float,...         0.00%       0.000us         0.00%       0.000us       0.000us     193.467us        19.24%     193.467us      64.489us             3  \n",
      "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us     160.189us        15.93%     160.189us      80.094us             2  \n",
      "void cudnn::winograd_nonfused::winogradForwardOutput...         0.00%       0.000us         0.00%       0.000us       0.000us     133.756us        13.30%     133.756us      66.878us             2  \n",
      "                                           aten::linear         0.26%      15.420us         4.96%     295.775us      98.592us       0.000us         0.00%     107.870us      35.957us             3  \n",
      "                                            aten::addmm         2.67%     159.166us         3.95%     235.496us      78.499us     107.870us        10.73%     107.870us      35.957us             3  \n",
      "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us      96.446us         9.59%      96.446us      48.223us             2  \n",
      "                                  volta_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.959us         6.86%      68.959us      34.479us             2  \n",
      "                         volta_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      20.768us         2.07%      20.768us      20.768us             1  \n",
      "                                            aten::relu_         3.11%     185.426us         7.77%     462.819us      30.855us       0.000us         0.00%      19.038us       1.269us            15  \n",
      "                                       aten::clamp_min_         2.84%     169.263us         4.66%     277.393us      18.493us      19.038us         1.89%      19.038us       1.269us            15  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.958ms\n",
      "Self CUDA time total: 1.006ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "imgs, labels = next(iter(testloader_c100))\n",
    "imgs = imgs.to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"inference\"):\n",
    "        _ = pruned_c100(imgs)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa8dbd",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f0b8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import io\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetTotalEnergyConsumption\n",
    "import thop.profile\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31a30c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_efficiency(model, dataloader, device, runs=100):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    nvmlInit()\n",
    "    gpu = nvmlDeviceGetHandleByIndex(0)\n",
    "    start_energy = nvmlDeviceGetTotalEnergyConsumption(gpu)\n",
    "\n",
    "    total_time, total_mem, correct1, correct5 = 0, 0, 0, 0\n",
    "    for _ in range(runs):\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        start_t = time.time()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        total_time += (end_t - start_t) * 1000\n",
    "        total_mem += torch.cuda.memory_allocated(device) / (1024 ** 2)\n",
    "        top5_pred = outputs.topk(5, dim=1).indices\n",
    "        top1_pred = outputs.argmax(dim=1)\n",
    "        correct1 += (top1_pred == labels).sum().item()\n",
    "        correct5 += sum(labels[i] in top5_pred[i] for i in range(len(labels)))\n",
    "    total = len(labels)\n",
    "    top1_acc = 100 * correct1 / (total * runs)\n",
    "    top5_acc = 100 * correct5 / (total * runs)\n",
    "\n",
    "    end_energy = nvmlDeviceGetTotalEnergyConsumption(gpu)\n",
    "    avg_energy = (end_energy - start_energy) / runs\n",
    "    avg_latency = total_time / runs\n",
    "    avg_mem = total_mem / runs\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device) / (1024 ** 2)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buf)\n",
    "    model_size = len(buf.getvalue()) / (1024 ** 2)\n",
    "\n",
    "    try:\n",
    "        macs, _ = thop.profile(model, inputs=(images,), verbose=False)\n",
    "    except Exception:\n",
    "        macs = float(\"nan\")\n",
    "    print(\"\\n========== Profiling Summary ==========\")\n",
    "    print(f\"Runs:            {runs}\")\n",
    "    print(f\"Model Size:      {model_size:.2f} MB\")\n",
    "    print(f\"Average Latency: {avg_latency:.2f} ms\")\n",
    "    print(f\"Peak Memory:     {peak_mem:.2f} MB\")\n",
    "    print(f\"Mean Memory:     {avg_mem:.2f} MB\")\n",
    "    print(f\"Energy / Run:    {avg_energy:.2f} mJ\")\n",
    "    print(f\"Top-1 Accuracy:  {top1_acc:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy:  {top5_acc:.2f}%\")\n",
    "    print(f\"MACs / Batch:    {macs / 1e6:.2f} M\")\n",
    "    print(\"=======================================\\n\")\n",
    "\n",
    "    return {\n",
    "        \"model_size_mb\": model_size,\n",
    "        \"latency_ms\": avg_latency,\n",
    "        \"avg_mem_mb\": avg_mem,\n",
    "        \"peak_mem_mb\": peak_mem,\n",
    "        \"energy_mJ\": avg_energy,\n",
    "        \"top1_acc\": top1_acc,\n",
    "        \"top5_acc\": top5_acc,\n",
    "        \"macs\": macs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "726c76ce-c37f-44c1-914a-5b9c86d73bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_c10.load_state_dict(torch.load(\"vgg16bn_pruned_10.pth\"))\n",
    "pruned_c100.load_state_dict(torch.load(\"vgg16bn_pruned_100.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24333ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Profiling Summary ==========\n",
      "Runs:            100\n",
      "Model Size:      8.97 MB\n",
      "Average Latency: 2.19 ms\n",
      "Peak Memory:     76.75 MB\n",
      "Mean Memory:     39.78 MB\n",
      "Energy / Run:    735.93 mJ\n",
      "Top-1 Accuracy:  48.44%\n",
      "Top-5 Accuracy:  82.81%\n",
      "MACs / Batch:    1980.52 M\n",
      "=======================================\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::conv2d         0.25%      19.350us        81.02%       6.161ms     473.953us       0.000us         0.00%       3.236ms     248.901us            13  \n",
      "                                      aten::convolution         0.68%      51.760us        80.77%       6.142ms     472.465us       0.000us         0.00%       3.236ms     248.901us            13  \n",
      "                                     aten::_convolution         1.59%     121.139us        80.09%       6.090ms     468.483us       0.000us         0.00%       3.236ms     248.901us            13  \n",
      "                                aten::cudnn_convolution        66.02%       5.021ms        74.91%       5.697ms     438.212us       3.053ms        73.69%       3.053ms     234.863us            13  \n",
      "                                       cudaLaunchKernel        13.19%       1.003ms        13.19%       1.003ms      10.340us       0.000us         0.00%       0.000us       0.000us            97  \n",
      "                                       aten::batch_norm         0.36%      27.660us         7.67%     583.018us      44.848us       0.000us         0.00%     582.513us      44.809us            13  \n",
      "                           aten::_batch_norm_impl_index         0.42%      31.680us         7.30%     555.358us      42.720us       0.000us         0.00%     582.513us      44.809us            13  \n",
      "                                 aten::cudnn_batch_norm         2.37%     180.130us         6.89%     523.678us      40.283us     582.513us        14.06%     582.513us      44.809us            13  \n",
      "                                            aten::relu_         0.56%      42.790us         3.92%     297.818us      19.855us       0.000us         0.00%     159.092us      10.606us            15  \n",
      "                                  cudaDeviceSynchronize         3.51%     266.609us         3.51%     266.609us     266.609us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.605ms\n",
      "Self CUDA time total: 4.144ms\n",
      "\n",
      "\n",
      "========== Profiling Summary ==========\n",
      "Runs:            100\n",
      "Model Size:      9.15 MB\n",
      "Average Latency: 2.27 ms\n",
      "Peak Memory:     77.40 MB\n",
      "Mean Memory:     39.80 MB\n",
      "Energy / Run:    753.85 mJ\n",
      "Top-1 Accuracy:  1.56%\n",
      "Top-5 Accuracy:  10.94%\n",
      "MACs / Batch:    1983.47 M\n",
      "=======================================\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaDeviceSynchronize        57.97%       3.278ms        57.97%       3.278ms       3.278ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                           aten::conv2d         0.30%      16.790us        22.86%       1.293ms      99.468us       0.000us         0.00%       3.230ms     248.463us            13  \n",
      "                                      aten::convolution         0.67%      37.920us        22.57%       1.276ms      98.177us       0.000us         0.00%       3.230ms     248.463us            13  \n",
      "                                     aten::_convolution         1.54%      86.930us        21.90%       1.238ms      95.260us       0.000us         0.00%       3.230ms     248.463us            13  \n",
      "                                       cudaLaunchKernel        16.71%     944.876us        16.71%     944.876us       9.741us       0.000us         0.00%       0.000us       0.000us            97  \n",
      "                                aten::cudnn_convolution         6.25%     353.389us        15.98%     903.595us      69.507us       3.047ms        73.53%       3.047ms     234.421us            13  \n",
      "                                       aten::batch_norm         0.30%      16.910us         9.28%     524.870us      40.375us       0.000us         0.00%     582.577us      44.814us            13  \n",
      "                           aten::_batch_norm_impl_index         0.54%      30.730us         8.98%     507.960us      39.074us       0.000us         0.00%     582.577us      44.814us            13  \n",
      "                                 aten::cudnn_batch_norm         3.04%     171.860us         8.44%     477.230us      36.710us     582.577us        14.06%     582.577us      44.814us            13  \n",
      "                                            aten::relu_         0.72%      41.000us         5.31%     300.519us      20.035us       0.000us         0.00%     160.049us      10.670us            15  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.655ms\n",
      "Self CUDA time total: 4.145ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "evaluation_c10 = evaluate_model_efficiency(pruned_c10, testloader_c10, device)\n",
    "\n",
    "pruned_c10.eval()\n",
    "inputs = torch.randn(256, 3, 32, 32).to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if torch.cuda.is_available() else [ProfilerActivity.CPU]) as prof:\n",
    "    with torch.no_grad():\n",
    "        pruned_c10(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "evaluation_c100 = evaluate_model_efficiency(pruned_c100, testloader_c100, device)\n",
    "\n",
    "pruned_c100.eval()\n",
    "inputs = torch.randn(256, 3, 32, 32).to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if torch.cuda.is_available() else [ProfilerActivity.CPU]) as prof:\n",
    "    with torch.no_grad():\n",
    "        pruned_c100(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
